- name: pvp ovs-kernel DUT setup
  hosts: dut
  vars_files:
    - ./test_settings.yml
  tasks:
  - debug:
      msg: Debug mode is enabled
    when: redhat_debug_mode == true

############################################
# Get needed cpu list #
############################################

  - name: Get dut_isolated_cpus
    shell: ./get_cpulist.sh {{ dut_interface_1_pciid }} dut_isolated_cpus
    register: dut_isolated_cpus
  - name: Get vcpu_0
    shell: ./get_cpulist.sh {{ dut_interface_1_pciid }} vcpu_0
    register: vcpu_0
  - name: Get vcpu_1
    shell: ./get_cpulist.sh {{ dut_interface_1_pciid }} vcpu_1
    register: vcpu_1
  - name: Get vcpu_2
    shell: ./get_cpulist.sh {{ dut_interface_1_pciid }} vcpu_2
    register: vcpu_2
  - name: Get vcpu_3
    shell: ./get_cpulist.sh {{ dut_interface_1_pciid }} vcpu_3
    register: vcpu_3
  - name: Get vcpu_emulator
    shell: ./get_cpulist.sh {{ dut_interface_1_pciid }} vcpu_emulator
    register: vcpu_emulator

#######################################
# Release the DPDK NIC back to kernel #
# #####################################

  - name: Start openvswitch
    service:
      name: openvswitch
      state: started
  - name: Delete ovs bridge
    shell: ovs-vsctl --if-exists del-br ovs_pvp_br0
  - name: Disable dpdk
    shell: ovs-vsctl set Open_vSwitch . other_config:dpdk-init=false
  - name: Stop openvswitch
    service:
      name: openvswitch
      state: stopped
  - name: Unbind nic from dpdk
    shell: driverctl -v unset-override {{ dut_interface_1_pciid }}
  - name: enable nic
    shell: ip link set {{ dut_interface_1 }} up
  - name: restart service openvswitch
    systemd:
      name: openvswitch
      enabled: no
      state: restarted
      daemon_reload: yes

#################
# Re-config OVS #
#################

  - name: Recreate ovs
    shell: ovs-vsctl add-br ovs_pvp_br0
  - name: Add nic into ovs
    shell: |
      ip link set {{ dut_interface_1 }} up
      ovs-vsctl add-port ovs_pvp_br0 {{ dut_interface_1 }} -- set Interface {{ dut_interface_1 }} ofport_request=1
  - name: Restart openvswitch
    service:
      name: openvswitch
      state: restarted

###################
# Create  VM #
# #################

  # remove all existing vms
  - name: list all VMs
    virt:
      command: list_vms
    register: all_vms
  - name: destroy all vms
    virt:
      name: "{{ item }}"
      command: destroy
    ignore_errors: True
    loop: "{{ all_vms.list_vms }}"
  - name: undefine all vms
    virt:
      name: "{{ item }}"
      command: undefine
    loop: "{{ all_vms.list_vms }}"

  # customize vm image
  - name: Folder for vm image
    file:
      state: directory
      path: /opt/images
  - name: Copy image to /opt/images
    copy:
      src: "{{ rhel_guest_image_path }}"
      dest: /opt/images/rhel_guest_image_pvp_kernel.qcow2
      remote_src: yes

  - name: Change passwd to root for vm
    shell: LIBGUESTFS_BACKEND=direct virt-customize -a /opt/images/rhel_guest_image_pvp_kernel.qcow2 --root-password password:root --uninstall cloud-init

  #set static IP address 192.168.122.123 for internet access in guest g1
  - shell: virsh net-list | grep default || virsh net-define /usr/share/libvirt/networks/default.xml
  - shell: virsh net-autostart default
  - shell: virsh net-list | grep default | grep active || virsh net-start default
  - shell: >
      virsh net-dumpxml default | grep "mac='52:54:00:01:02:03'" &&
      virsh net-update default modify ip-dhcp-host "<host mac='52:54:00:01:02:03' ip='192.168.122.5'/>" --live --config ||
      virsh net-update default add ip-dhcp-host "<host mac='52:54:00:01:02:03' ip='192.168.122.5'/>" --live --config

  - name: create VM
    shell: virt-install --connect=qemu:///system --network bridge=ovs_pvp_br0,virtualport_type=openvswitch,model=virtio --network network=default,mac=52:54:00:01:02:03 --name=rhel_loopback_kerneldp --disk path=/opt/images/rhel_guest_image_pvp_kernel.qcow2,format=qcow2 --ram 8192 --memorybacking hugepages=on,size=1024,unit=M,nodeset=0,access_mode=shared --vcpus=4,cpuset={{ vcpu_0.stdout }},{{ vcpu_1.stdout }},{{ vcpu_2.stdout }},{{ vcpu_3.stdout }} --check-cpu --cpu mode=host-passthrough,+pdpe1gb,cell0.id=0,cell0.cpus=0,cell0.memory=8388608 --numatune mode=strict,nodeset=0 --nographics --noautoconsole --import

  - name: Wait vm to start
    pause:
      seconds: 60

  - name: Setting cpu pin for vcpu 0
    shell: virsh vcpupin rhel_loopback_kerneldp 0 {{ vcpu_0.stdout }}
  - name: Setting cpu pin for vcpu 1
    shell: virsh vcpupin rhel_loopback_kerneldp 1 {{ vcpu_1.stdout }}
  - name: Setting cpu pin for vcpu 2
    shell: virsh vcpupin rhel_loopback_kerneldp 2 {{ vcpu_2.stdout }}
  - name: Setting cpu pin for vcpu 3
    shell: virsh vcpupin rhel_loopback_kerneldp 3 {{ vcpu_3.stdout }}
  - name: Setting emulator pin for guest
    shell: virsh emulatorpin rhel_loopback_kerneldp {{ vcpu_emulator.stdout }}
  - name: copying virsh console script to default location
    copy:
      src: ./vm.sh
      dest: ~/vm.sh
      mode: "777"
  - name: Logging into vm rhel_loopback_kerneldp
    shell: ~/vm.sh login_vm rhel_loopback_kerneldp
  - name: Setting up subscription manager step 1 on rhel_loopback_kerneldp
    shell: ~/vm.sh run_cmd rhel_loopback_kerneldp "subscription-manager register --username={{ rh_sub_username }} --password={{ rh_sub_pass }}"
    when: not qe_subscription_mode
  - name: Setting up subscription manager step 2 on rhel_loopback_kerneldp
    shell: ~/vm.sh run_cmd rhel_loopback_kerneldp "subscription-manager attach --pool={{ rh_sub_pool_id }}"
    when: not qe_subscription_mode
  - name: Using QE Secret sauce to add subscription for repos
    shell: ~/vm.sh run_cmd rhel_loopback_kerneldp "{{ qe_subscription_command }}"
    retries: 5
    delay: 3
    when: qe_subscription_mode
  - name: subscribing to appstream on VM rhel_loopback_kerneldp
    shell: ~/vm.sh run_cmd rhel_loopback_kerneldp "subscription-manager repos --enable rhel-8-for-x86_64-appstream-rpms || subscription-manager repos --enable rhel-8-for-x86_64-appstream*-rpms"
  - name: Running yum commandset step 1 on rhel_loopback_kerneldp
    shell: ~/vm.sh run_cmd rhel_loopback_kerneldp "yum -y clean all"
  - name: Running yum commandset step 2 on rhel_loopback_kerneldp
    shell: ~/vm.sh run_cmd rhel_loopback_kerneldp "yum -y update"
  - name: Running yum commandset step 3 on rhel_loopback_kerneldp
    shell: ~/vm.sh run_cmd rhel_loopback_kerneldp "yum -y install driverctl gcc kernel-devel numactl-devel tuned-profiles-cpu-partitioning wget libibverbs dpdk-tools"
  - name: Running yum commandset step 4 on rhel_loopback_kerneldp
    shell: ~/vm.sh run_cmd rhel_loopback_kerneldp "yum -y update kernel"
  - name: Modifying grub for tuning on rhel_loopback_kerneldp
    shell: ~/vm.sh run_cmd rhel_loopback_kerneldp "grubby --args='isolcpus=1,2,3 default_hugepagesz=1G hugepagesz=1G hugepages=2' --update-kernel=ALL"
  - name: Setting vfio options on rhel_loopback_kerneldp
    shell: ~/vm.sh run_cmd rhel_loopback_kerneldp "echo 'options vfio enable_unsafe_noiommu_mode=1' > /etc/modprobe.d/vfio.conf"
  - name: Binding nic to vfio-pci on rhel_loopback_kerneldp
    shell: ~/vm.sh run_cmd rhel_loopback_kerneldp "driverctl -v set-override 0000:00:02.0 vfio-pci"
  - name: Starting tuned service step 1 on rhel_loopback_kerneldp
    shell: ~/vm.sh run_cmd rhel_loopback_kerneldp "systemctl enable tuned"
  - name: Starting runed service step 2 on rhel_loopback_kerneldp
    shell: ~/vm.sh run_cmd rhel_loopback_kerneldp "systemctl start tuned"
  - name: Setting isolated cores for tuning profile on rhel_loopback_kerneldp
    shell: ~/vm.sh run_cmd rhel_loopback_kerneldp "grep -e '^isolated_cores=1,2,3' /etc/tuned/cpu-partitioning-variables.conf || echo isolated_cores=1,2,3 >> /etc/tuned/cpu-partitioning-variables.conf"
  - name: Starting tuned profile cpu-partitioning on rhel_loopback_kerneldp
    shell: ~/vm.sh run_cmd rhel_loopback_kerneldp "tuned-adm profile cpu-partitioning"
  - name: Rebooting vm rhel_loopback_kerneldp step 1
    virt:
      name: rhel_loopback_kerneldp
      state: shutdown
  - name: Wait system some time to shutdown
    pause:
      seconds: 5
  - name: Rebooting vm rhel_loopback_kerneldp step 2
    virt:
      name: rhel_loopback_kerneldp
      state: running
  - name: Wait vm to start
    pause:
      seconds: 60
  - name: Logging into VM rhel_loopback_kerneldp
    shell: ~/vm.sh login_vm rhel_loopback_kerneldp
  - name: Logging into vm rhel_loopback_kerneldp
    shell: ~/vm.sh login_vm rhel_loopback_kerneldp
  - name: Getting IP address from VM
    shell: ~/vm.sh run_cmd rhel_loopback_kerneldp "ip a | grep inet | grep brd | awk '{ print \$2 }'" | grep -A 1 "ip a \| grep inet \| grep brd"   | tail -n 1
    register: vm_ip
  - debug:
      msg: Please note the ip address of the VM as it will be needed when executing the pvp test scripts {{ vm_ip.stdout }}

