- name: Tc flower offload setup
  hosts: dut
  vars_files:
    - ./test_settings.yml
  tasks:

    # Install required packages
    - name: Install required packages
      dnf:
        name:
          - '@virt'
          - libvirt
          - virt-install
          - libguestfs-tools
        state: present

    # Install openvswitch
    - name: Install openvswitch
      dnf:
        name:
          - "{{ ovs_selinux_rpm_path }}"
          - "{{ ovs_rpm_path }}"
        state: present
      when: redhat_debug_mode == True

    # Install EPEL repositories
    - name: Install EPEL repositories
      dnf:
        name: https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
        state: present

    - name: Install packages from EPEL repo
      dnf:
        name: sshpass
        state: present

    - name: Remove EPEL repo to avoid conflict
      dnf:
        name: epel-release-7
        state: absent

    # Python settings
    - name: Link /usr/bin/python to /usr/bin/python3
      file:
        src: "/usr/bin/python3"
        dest: "/usr/bin/python"
        state: link
    - name: Link pip to pip3
      file:
        src: "/usr/bin/pip3"
        dest: "/usr/bin/pip"
        state: link

    # Disable hugepage settings if exists
    - name: Cheking if hugepage setting exists
      shell:
        cmd: >
          grep default_hugepagesz=1G /proc/cmdline ||
          grep hugepagesz=1G /proc/cmdline ||
          grep hugepages=32 /proc/cmdline
      failed_when: false
      ignore_errors: yes
      register: hugepage_ok

    - name: Remove hugepage settings
      shell:
        cmd: >
          grubby -remove-args="default_hugepagesz" -remove-args="hugepagesz" -remove-args="hugepages" --update-kernel=$(grubby --default-kernel)" &&
          reboot
      when: hugepage_ok.rc == 0

    - name: setup tc offload for specific card
      import_tasks: "{{ tc_offload_card_type }}.yml"

    - name: Start openvswitch service
      service:
        name: openvswitch
        state: started

    - name: Enable hw-offload and restart openvswitch service
      shell: >
        cmd:
          ovs-vsctl set Open_vSwitch . other_config:hw-offload=true
          systemctl restart openvswitch

    - name: setup OVS bridge
      shell: >
        cmd:
          ovs-vsctl --if-exists del-br ovs_pvp_br0 &&
          ovs-vsctl add-br ovs_pvp_br0 &&
          ovs-vsctl add-port ovs_pvp_br0 {{ pf_rep.stdout }} -- set Interface {{ pf_rep.stdout }} ofport_request=1 &&
          ovs-vsctl add-port ovs_pvp_br0 {{ vf_rep.stdout }} -- set Interface {{ vf_rep.stdout }} ofport_request=2

    # Get needed cpu list #
    - name: Copy up cpulist script to remote DUT
      copy:
        src: get_cpulist.sh
        dest: /root/get_cpulist.sh
    - name: Changing perm of "/root/get_cpu_list.sh", adding "+x"
      file: dest=/root/get_cpulist.sh mode=a+x
    - name: Get dut_isolated_cpus
      shell: ./get_cpulist.sh {{ dut_interface_1_pciid }} dut_isolated_cpus
      register: dut_isolated_cpus
    - name: Get vcpu_1
      shell: ./get_cpulist.sh {{ dut_interface_1_pciid }} vcpu_1
      register: vcpu_1
    - name: Get vcpu_2
      shell: ./get_cpulist.sh {{ dut_interface_1_pciid }} vcpu_2
      register: vcpu_2
    - name: Get vcpu_3
      shell: ./get_cpulist.sh {{ dut_interface_1_pciid }} vcpu_3
      register: vcpu_3
    - name: Get vcpu_4
      shell: ./get_cpulist.sh {{ dut_interface_1_pciid }} vcpu_4
      register: vcpu_4

    #   Create vm #
    - name: Folder for vm image
      file:
        state: directory
        path: /opt/images
    - name: Copy image to /opt/images
      copy:
        src: "{{ rhel_guest_image_path }}"
        dest: /opt/images/rhel-guest-image-8.0-x86_64-kvm-tc.qcow2
        remote_src: yes

    - name: Change passwd to root for vm
      shell: LIBGUESTFS_BACKEND=direct virt-customize -a /opt/images/rhel-guest-image-8.0-x86_64-kvm-tc.qcow2 --root-password password:root --uninstall cloud-init

    - name: Create vm
      shell: virt-install --connect=qemu:///system --network none --host-device {{ vf_pciiid.stdout }},driver_name=vfio --network network=default --name=rhel_loopback_tcflower --disk path=/opt/images/rhel-guest-image-8.0-x86_64-kvm-tc.qcow2,format=qcow2 --ram 8192 --vcpus=4,cpuset={{ vcpu_1.stdout }},{{ vcpu_2.stdout }},{{ vcpu_3.stdout }},{{ vcpu_4.stdout }}  --check-cpu --cpu host,+pdpe1gb,cell0.id=0,cell0.cpus=0,cell0.memory=8388608 --numatune mode=strict,nodeset=0 --nographics --noautoconsole --import

    - name: Wait vm to start
      pause:
        seconds: 60
    - name: copying virsh console script to default location
      copy:
        src: ./vm.sh
        dest: ~/vm.sh
        mode: "777"
    #- name: Delete nmcli connection
    #  shell: ~/vm.sh run_cmd rhel_loopback_tcflower "nmcli c | grep -o --  '[0-9a-fA-F]\{8\}-[0-9a-fA-F]\{4\}-[0-9a-fA-F]\{4\}-[0-9a-fA-F]\{4\}-[0-9a-fA-F]\{12\}' | xargs -n 1 nmcli c delete uuid"
    #- name: Create nmcli connection for ovs-dpdk
    #  shell: ~/vm.sh run_cmd rhel_loopback_tcflower "nmcli con add con-name ovs-dpdk ifname $(for dev in `find /sys/class/net/ -type l | awk -F'/' '!/lo|sit|usb|ib/{print $5}' | sort -u`; do if ethtool -i $dev | grep driver | grep -q virtio; then continue; else echo $dev;break; fi;done) type ethernet ip4 1.1.1.1/24"
    #- name: Create nmcli connection for management
    #  shell: ~/vm.sh run_cmd rhel_loopback_tcflower "nmcli con add con-name management ifname $(for dev in `find /sys/class/net/ -type l | awk -F'/' '!/lo|sit|usb|ib/{print $5}' | sort -u`; do if ethtool -i $dev | grep -q virtio; then echo $dev;break; fi; done) type ethernet"
    - name: Setting up subscription manager step 1 on rhel_loopback_tcflower
      shell: ~/vm.sh run_cmd rhel_loopback_tcflower "subscription-manager register --username={{ rh_sub_username }} --password={{ rh_sub_pass }} --baseurl=cdn.stage.redhat.com --serverurl subscription.rhsm.stage.redhat.com"
      when: not qe_subscription_mode
    - name: Setting up subscription manager step 2 on rhel_loopback_tcflower
      shell: ~/vm.sh run_cmd rhel_loopback_tcflower "subscription-manager attach --pool={{ rh_sub_pool_id }}"
      when: not qe_subscription_mode
    - name: Using QE Secret sauce to add subscription for repos
      shell: ~/vm.sh run_cmd rhel_loopback_tcflower "{{ qe_subscription_command }}"
      when: qe_subscription_mode
    - name: setting up guest
      shell: 
        cmd: >
          ~/vm.sh login_vm rhel_loopback_tcflower &&
          ~/vm.sh run_cmd rhel_loopback_tcflower "subscription-manager repos --enable rhel-8-for-x86_64-appstream-rpms" &&
          ~/vm.sh run_cmd rhel_loopback_tcflower "yum -y clean all" &&
          ~/vm.sh run_cmd rhel_loopback_tcflower "yum -y install driverctl gcc kernel-devel numactl-devel tuned-profiles-cpu-partitioning wget libibverbs dpdk" &&
          ~/vm.sh run_cmd rhel_loopback_tcflower "grubby --args='default_hugepagesz=1G hugepagesz=1G hugepages=2' --update-kernel=\$(grubby --default-kernel)" &&
          ~/vm.sh run_cmd rhel_loopback_tcflower "echo 'options vfio enable_unsafe_noiommu_mode=1' > /etc/modprobe.d/vfio.conf" &&
          ~/vm.sh run_cmd rhel_loopback_tcflower "echo isolated_cores=1,2,3 >> /etc/tuned/cpu-partitioning-variables.conf" &&
          ~/vm.sh run_cmd rhel_loopback_tcflower "tuned-adm profile cpu-partitioning" &&
          ~/vm.sh run_cmd rhel_loopback_tcflower "systemctl enable tuned" &&
          ~/vm.sh run_cmd rhel_loopback_tcflower "systemctl start tuned"

    - name: Rebooting vm rhel_loopback_tcflower step 1
      virt:
        name: rhel_loopback_tcflower
        state: shutdown
    - name: Wait system some time to shutdown
      pause:
        seconds: 5
    - name: Rebooting vm rhel_loopback_tcflower step 2
      virt:
        name: rhel_loopback_tcflower
        state: running
    - name: Wait vm to start
      pause:
        seconds: 60

    - name: bind nic to vfio-pci
      shell: ~/vm.sh run_cmd rhel_loopback_tcflower "driverctl -v set-override 0000:00:04.0 vfio-pci"
      when: tc_offload_card_type != "mlx5_core"

    - name: Logging into VM rhel_loopback_tcflower
      shell: ~/vm.sh login_vm rhel_loopback_tcflower
